{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbc665ff-e0ae-4e92-bc05-fcc6ea9e1cda",
   "metadata": {},
   "source": [
    "Muhammad Nabil Bin Muhamad - IS01082117\n",
    "Ahmad Amirul Aizad Bin Rosmadi - IS01082507"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7ae0d6a9-de2d-403c-91f9-406d78e878be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0641f05a-912a-4aa6-bd2f-4f7af9338205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\victus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\victus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\victus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\victus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6aad1992-9903-4ae2-92da-963b6da914e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2df5fffa-ad4a-40c7-8f47-91388ea134b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d4690492-2a99-431c-8bcd-39f9c827c001",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Score', 'Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "03509444-cd98-4b01-b103-c903279ce1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3e1c26be-b322-4a4a-beb0-014b8c137200",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Score'] != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9859540b-ee4e-4419-949c-e8aca82835c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment'] = df['Score'].apply(lambda x: 1 if x > 3 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8786e33a-d59f-4626-be90-c9807475d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)      # remove numbers\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "640f7a29-92de-4d6c-a5d3-9922a10e5009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# c. Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c7e9f918-4e77-4868-8ae3-78753e827b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "def stem_words(tokens):\n",
    "    return [stemmer.stem(word) for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "25a550c6-07c6-455f-ae5c-1647d3306a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_words(tokens):\n",
    "    return [lemmatizer.lemmatize(word) for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "865711f8-4bbe-49cc-830f-6066a7d5fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_preprocess_pipeline(text):\n",
    "    text = clean_text(text)\n",
    "    tokens = tokenize_text(text)\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    tokens = lemmatize_words(tokens)  # You can use stem_words(tokens) instead\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ab5ca8d1-3ac8-4697-a5c6-8ba8ccb7ee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Processed_Text'] = df['Text'].apply(full_preprocess_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d725935b-96f8-471b-b605-d8b122444bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Processed_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>product arrived labeled jumbo salted peanutsth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>confection around century light pillowy citrus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  I have bought several of the Vitality canned d...   \n",
       "1  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  This is a confection that has been around a fe...   \n",
       "3  If you are looking for the secret ingredient i...   \n",
       "4  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "                                      Processed_Text  \n",
       "0  bought several vitality canned dog food produc...  \n",
       "1  product arrived labeled jumbo salted peanutsth...  \n",
       "2  confection around century light pillowy citrus...  \n",
       "3  looking secret ingredient robitussin believe f...  \n",
       "4  great taffy great price wide assortment yummy ...  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Text', 'Processed_Text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "391948e7-1f8e-4d23-aa01-d23fbeb664db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\victus\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\victus\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\victus\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\victus\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\victus\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d0d9cb2f-4908-48d9-8eab-935b2bd1a921",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Split features and labels\n",
    "X_raw = df['Processed_Text']   # text data\n",
    "y = df['Sentiment']            # labels (0 = negative, 1 = positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9b945455-0544-4451-b96e-22da41e10acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW matrix shape: (525814, 203766)\n"
     ]
    }
   ],
   "source": [
    "# Initialize CountVectorizer (BoW)\n",
    "bow_vectorizer = CountVectorizer()\n",
    "\n",
    "# Transform text data into feature vectors\n",
    "X_bow = bow_vectorizer.fit_transform(X_raw)\n",
    "\n",
    "# View shape of feature matrix\n",
    "print(\"BoW matrix shape:\", X_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "55695777-0bdb-4360-ab3f-2c5db25611e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (525814, 203766)\n"
     ]
    }
   ],
   "source": [
    "# Initialize TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Transform text data into TF-IDF feature vectors\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X_raw)\n",
    "\n",
    "# View shape of feature matrix\n",
    "print(\"TF-IDF matrix shape:\", X_tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3def8d0b-6de0-4f12-a634-a709620a04b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample BoW Features: ['__' '___' '____' '_____' '______' '_______' '________' '__________'\n",
      " '___________' '________________________________________']\n",
      "Sample TF-IDF Features: ['__' '___' '____' '_____' '______' '_______' '________' '__________'\n",
      " '___________' '________________________________________']\n"
     ]
    }
   ],
   "source": [
    "# Print sample feature names\n",
    "print(\"Sample BoW Features:\", bow_vectorizer.get_feature_names_out()[:10])\n",
    "print(\"Sample TF-IDF Features:\", tfidf_vectorizer.get_feature_names_out()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f2b0357b-7f61-428c-a546-83bcd6d8318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1984abab-5162-4299-9e86-a96927511429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into 80% train and 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4e2bb6dc-064d-47ab-9b03-d4a7c2934261",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "y_pred_nb = nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f17aa306-0907-4b2b-8bc3-e47c4dfa08be",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = LinearSVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "19e5f3c2-c115-40ac-8786-eaac6229c216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Evaluation for Naive Bayes\n",
      "Accuracy: 0.8567747211471716\n",
      "Confusion Matrix:\n",
      " [[ 1412 14967]\n",
      " [   95 88689]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.09      0.16     16379\n",
      "           1       0.86      1.00      0.92     88784\n",
      "\n",
      "    accuracy                           0.86    105163\n",
      "   macro avg       0.90      0.54      0.54    105163\n",
      "weighted avg       0.87      0.86      0.80    105163\n",
      "\n",
      "--------------------------------------------------\n",
      "ðŸ“Š Evaluation for Support Vector Machine\n",
      "Accuracy: 0.9449711400397478\n",
      "Confusion Matrix:\n",
      " [[12507  3872]\n",
      " [ 1915 86869]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.76      0.81     16379\n",
      "           1       0.96      0.98      0.97     88784\n",
      "\n",
      "    accuracy                           0.94    105163\n",
      "   macro avg       0.91      0.87      0.89    105163\n",
      "weighted avg       0.94      0.94      0.94    105163\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    print(f\"ðŸ“Š Evaluation for {model_name}\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_true, y_pred))\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Evaluate each\n",
    "evaluate_model(y_test, y_pred_nb, \"Naive Bayes\")\n",
    "evaluate_model(y_test, y_pred_svm, \"Support Vector Machine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458e9a37-f7af-4c2c-8543-af4c69a8cbc9",
   "metadata": {},
   "source": [
    "Name 1: Muhammad Nabil Bin Muhamad\n",
    "Student ID 1: IS01082117\n",
    "\n",
    "Name 2 : Ahmad Amirul Aizad Bin Rosmadi\n",
    "Student ID 2 : IS01082507\n",
    "\n",
    "In this lab assignment, for text pre-processing I (Nabil) and Aizad implemented 5 steps which are **1. Tokenization**, **2. Standardization**, **3. Stop Word Removal**, **4. Stemming**, **5. Lemmetization**. Then, we implemented and compared two machine learning models: **Multinomial Naive Bayes** and **Support Vector Machine (SVM)** for sentiment classification using the Amazon Fine Food Reviews dataset. I tried to include **Random Forest Regression** but our laptop takes time too long to run the Random Forest Regression so we give up. Sorry Madam Laila. Here are our findings :\n",
    "\n",
    "**Naive Bayes** is a simple, fast, and highly scalable classifier, especially effective for text classification tasks with a large feature space. It performed well and trained quickly, making it ideal for large datasets. However, it assumes feature independence, which may reduce accuracy when the text contains complex dependencies between words.\n",
    "\n",
    "**Support Vector Machine (SVM)**, on the other hand, produced higher accuracy and precision compared to Naive Bayes. SVM is powerful in handling high-dimensional data and works well with sparse features like TF-IDF. Its main downside is that it's computationally more intensive and slower to train, especially with large datasets.\n",
    "\n",
    "In summary, **SVM outperformed Naive Bayes in terms of accuracy**, but **Naive Bayes offers efficiency and simplicity**. The choice of model depends on the task requirementsâ€”speed vs performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cb5cf69d-f352-4f87-b004-117515a37303",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"preprocessed_reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa04bbb-a78a-4b64-bda3-8d77850c059d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
